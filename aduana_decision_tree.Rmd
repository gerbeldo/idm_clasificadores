---
title: "R Notebook"
output:
  html_document:
    df_print: paged
    highlight: kate
    theme:
      version: 4
      code_font: 
        google: JetBrains Mono
editor_options:
  chunk_output_type: console
  markdown:
    wrap: 72
---

# libraries and data loading

```{r}
library(tidyverse)
library(tidymodels)
library(tictoc)
```

Cargamos las bases de datos, prelimpiadas (eliminadas las tildes en dos variables).
Transformamos las variables `chr` en `factor`, y ademas varias de las numericas, que
no son numericas realmente, como el periodo de oficializacion, el capitulo y la partida.

```{r}
aduana <- read_csv("datasets/aduana_train.csv") %>%
  janitor::clean_names() %>%
  mutate(across(where(is.character), factor),
    periodo_oficializacion = factor(periodo_oficializacion),
    capitulo = factor(capitulo),
    partida = factor(partida)
  )

aduana_test_final <- read_csv("datasets/aduana_train.csv") %>%
  janitor::clean_names() %>%
  mutate(across(where(is.character), factor),
    periodo_oficializacion = factor(periodo_oficializacion),
    capitulo = factor(capitulo),
    partida = factor(partida)
  )
```

# preparation

dividimos data para training, y de ahi armamos folds para cross-validation (10-fold cv)

```{r}
aduana_split <- initial_split(aduana, prop = 0.85, strata = canal)
aduana_train <- training(aduana_split)

aduana_folds <- vfold_cv(aduana_train, v = 10, strata = canal)
```

Ademas definimos una funcion con las metricas de performance que nos interesan
para evaluar la optimizacion de hiperparametros.

```{r}
aduana_metrics <- metric_set(accuracy, sens, spec, roc_auc)
```


# decision tree


definimos receta de preprocesamiento. Para un arbol no hay que hacer mucho. Solo pooleo
niveles infrecuentes de las variables categoricas (<5%) en un nivel "other" 

```{r}
rec_dt <- recipe(canal ~ ., aduana_train) %>%
  step_other(all_nominal_predictors(), threshold = 0.05)

```


defino modelo, con parametros a tunear

```{r}
tree_model_tune <- decision_tree(tree_depth = tune(),
                                 cost_complexity = tune(),
                                 min_n = tune()) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
```

Con esto junto todo en un workflow, receta de preprocessing + modelo

```{r}
dt_tune_wkfl <- workflow() %>% 
  add_recipe(rec_dt) %>% 
  add_model(tree_model_tune)

```

Necesitamos una forma de samplear el espacio de parametros a explorar, para lo que 
usamos el metodo de latin hypercube sampling. La gracia es que ninguna de las combinaciones
repite valores de parametros, a diferencia de armar una grilla regular.

```{r}
dt_tune_grid <- grid_latin_hypercube(parameters(dt_tune_wkfl), size = 1000)
```


Tuneamos el modelo

```{r}
# tuneo
tic()
dt_tuning <- tune_grid(dt_tune_wkfl,
                       resamples = aduana_folds,
                       grid = dt_tune_grid,
                       metrics = aduana_metrics)
toc()
beepr::beep("coin")
```

Exploramos los modelos obtenidos y usamos accuracy como medida de decision.

```{r}
dt_tuning %>%
  collect_metrics() %>%
  arrange(.metric, desc(mean)) %>%
  filter(.config %in% configs$.config) %>% view

best_dt_params <- dt_tuning %>%
  select_best(metric = "accuracy")
```

Finalizamos el workflow, seteando los parametros a los valores que encontramos
en la optimizacion. Luego ajustamos el modelo con el training set completo

```{r}
dt_tune_final_wkfl <- dt_tune_wkfl %>% 
  finalize_workflow(best_dt_params)

tree_model <- dt_tune_final_wkfl %>% 
  fit(data = aduana)
```

Evaluamos el modelo con los datos de test

```{r}
tree_pred_class <- predict(tree_model,
                           new_data = aduana_test_final,
                           type = "class")

tree_pred_prob <- predict(tree_model,
                          new_data = aduana_test_final,
                          type = "prob")

# juntamos las predicciones en un unico tibble
tree_preds <- select(aduana_test_final, canal) %>% 
  bind_cols(tree_pred_class, tree_pred_prob)

# la ultima linea es necesaria para el area de la ROC
tree_preds %>%
  aduana_metrics(
  truth = canal,
  estimate = .pred_class,
  .pred_N, .pred_R, .pred_V
)

```

Deberia haber seteado seeds, pero con los parametros:

```{r}
#   param                estimate
#   <chr>                   <dbl>
# 1 cost_complexity  0.0000000999
# 2 tree_depth      15           
# 3 min_n           11      
```

Obtuvimos, en test:

```{r}
#   .metric  .estimate
#   <chr>        <dbl>
# 1 accuracy     0.922
# 2 sens         0.922
# 3 spec         0.963
# 4 roc_auc      0.987
```

